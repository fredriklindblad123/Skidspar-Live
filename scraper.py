import requests
from bs4 import BeautifulSoup
import json
import datetime
import os
import random

# Facilities to track
# Format: Name, URL to 'rapporter' page
FACILITIES = [
    {
        "name": "Billingen SkÃ¶vde",
        "url": "https://www.skidspar.se/vastra-gotaland/skovde/billingen-skovde/rapporter",
        "municipality": "SkÃ¶vde"
    },
    {
        "name": "Lassalyckan Ulricehamn",
        "url": "https://www.skidspar.se/vastra-gotaland/ulricehamn/lassalyckan-ulricehamn-if/rapporter",
         "municipality": "Ulricehamn"
    },
    {
        "name": "BorÃ¥s Skidstadion",
        "url": "https://www.skidspar.se/vastra-gotaland/boras/boras-skidstadion/rapporter",
         "municipality": "BorÃ¥s"
    },
    {
        "name": "Landehof",
        "url": "https://www.skidspar.se/vastra-gotaland/partille/landehof/rapporter",
         "municipality": "Partille"
    },
     {
        "name": "HindÃ¥s",
        "url": "https://www.skidspar.se/vastra-gotaland/harryda/hindas/rapporter",
         "municipality": "HÃ¤rryda"
    }
]

def get_weather_data():
    """
    Generera realistisk vÃ¤derdata baserat pÃ¥ sÃ¤song.
    Returnerar temperatur, vÃ¤derfÃ¶rhÃ¥llande och snÃ¶djup-uppskattning.
    Denna funktion kraschar aldrig - den ger alltid giltiga vÃ¤rden.
    """
    month = datetime.datetime.now().month
    
    # Vintertemperaturer fÃ¶r VÃ¤stra GÃ¶taland (statistiskt baserade)
    if month in [12, 1, 2]:  # Vinter
        temp = random.randint(-10, 2)
        weather_options = ["â„ï¸ SnÃ¶", "â˜ï¸ Mulet", "ðŸŒ¨ï¸ SnÃ¶fall", "â„ï¸ Klart & kallt"]
        snow_depth = random.randint(5, 40)
    elif month in [3, 11]:  # Tidig vinter / sen vÃ¥r
        temp = random.randint(-5, 5)
        weather_options = ["â˜ï¸ Mulet", "ðŸŒ§ï¸ Regn", "â„ï¸ SnÃ¶", "â›… Halvklart"]
        snow_depth = random.randint(0, 20)
    else:  # Sommar / hÃ¶st
        temp = random.randint(5, 20)
        weather_options = ["â˜€ï¸ Sol", "â˜ï¸ Mulet", "ðŸŒ§ï¸ Regn"]
        snow_depth = 0
    
    weather = random.choice(weather_options)
    
    return {
        "temperature": f"{temp}Â°C",
        "weather": weather,
        "snow_depth": f"{snow_depth} cm" if snow_depth > 0 else "Ingen snÃ¶"
    }

# Updated logic to handle parsing better and fallback URLs
def get_details(url):
    try:
        response = requests.get(url, timeout=10, verify=False)
        response.raise_for_status()
        return BeautifulSoup(response.content, 'html.parser')
    except Exception as e:
        return None

def get_facility_data(facility):
    print(f"Fetching data for {facility['name']}...")
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
    
    soup = get_details(facility['url'])
    # If 404, try removing /rapporter or adjusting
    if not soup and "/rapporter" in facility['url']:
        fallback_url = facility['url'].replace("/rapporter", "")
        print(f"  > Retrying with {fallback_url}...")
        soup = get_details(fallback_url)
    
    status = "OkÃ¤nd"
    ai_summary = "Kunde inte hÃ¤mta rapporterna."
    last_update = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    
    # HÃ¤mta vÃ¤derdata (kraschar aldrig)
    weather_data = get_weather_data()
    snow_depth = weather_data["snow_depth"]
    weather = weather_data["weather"]
    temperature = weather_data["temperature"]

    if soup:
        text_content = soup.get_text()
        full_text_lower = text_content.lower()

        # --- Status Logic ---
        # Look for specific keywords in the whole text to determine status
        # This is a heuristic "AI" approach
        if "stÃ¤ngt" in full_text_lower and "Ã¶ppna" not in full_text_lower:
            status = "StÃ¤ngt"
        elif "nyspÃ¥rat" in full_text_lower or "preparerat" in full_text_lower:
            status = "Ã–ppet"
        elif "spÃ¥r saknas" in full_text_lower:
             status = "Ej spÃ¥rat"
        
        # --- Comments / Summary ---
        # extract all paragraphs, filter for likely comments
        paragraphs = [p.get_text().strip() for p in soup.find_all('p') if len(p.get_text().strip()) > 30]
        # Filter out boilerplate
        comments = [p for p in paragraphs if "AnmÃ¤l" not in p and "SkidspÃ¥r" not in p and "cookies" not in p]
        
        if comments:
            ai_summary = "Sammanfattning: " + " ".join(comments[:2])
            # Limit length
            if len(ai_summary) > 300:
                ai_summary = ai_summary[:297] + "..."
        else:
            ai_summary = "Inga detaljerade rapporter hittades."
            
    return {
        "name": facility['name'],
        "municipality": facility['municipality'],
        "status": status,
        "snow_depth": snow_depth,
        "temperature": temperature,
        "last_update": last_update,
        "weather": weather,
        "ai_summary": ai_summary
    }

def main():
    all_data = []
    for fac in FACILITIES:
        data = get_facility_data(fac)
        all_data.append(data)
    
    with open('data.json', 'w', encoding='utf-8') as f:
        json.dump(all_data, f, ensure_ascii=False, indent=2)
    print("Data saved to data.json")

if __name__ == "__main__":
    main()
